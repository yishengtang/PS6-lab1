{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Warehouse\n",
    "\n",
    "The following script loads in data from two sources:\n",
    "1. AirBnB data from the Washington, D.C. Metro Area [http://insideairbnb.com/get-the-data]\n",
    "2. Crime data from the Washington, D.C. area [crimecards.dc.gov]\n",
    "\n",
    "The airbnb data is for the last 4 quarters starting from December 15th 2021 to September 14th 2022. For each of the 4 quarters, we create 4 tables from the AirBnB data:\n",
    "1. `listings`\n",
    "2. `neighborhoods` (spelled `neighbourhoods` in the AirBnB website)\n",
    "3. `reviews`\n",
    "4. `calendar`\n",
    "\n",
    "For the crime data, we create **TODO**\n",
    "\n",
    "### Notes for running this notebook\n",
    "* This notebook assumes that all source data .csv files are in the same directory as this script\n",
    "* The September 14th, 2022 `listings.csv` data source included a `source` column that the other `listings.csv` files did not. We chose to drop this column for that quarter because `source` was simply where the data was scraped from and we don't plan on using that\n",
    "* Order of import matters for `listings.csv` when using read_csv_auto. 11Jun, 14Sep, and 19Mar had a value, 558788119405795275, that couldn't be represented as an INTEGER (32-bit). If you import the December data first, then it defaults to storing this data as a BIGINT (64-bit), which seems to work. Alternatively, alter the column to BIGINT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We are using DuckDB version 0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database='ps6.duckdb', read_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data\n",
    "Reference: https://duckdb.org/docs/api/python/overview\n",
    "\n",
    "### 1. listings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team question: What was the reason for explicitly specifying the columns and types? Did the auto read csv not bring in the data correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con.execute('CREATE TABLE listings'\n",
    "#             '(id BIGINT,'\n",
    "#             'listing_url VARCHAR,'\n",
    "#             'scrape_id BIGINT,'\n",
    "#             'last_scraped DATE,'\n",
    "#             'source VARCHAR,'\n",
    "#             'name VARCHAR,'\n",
    "#             'description VARCHAR,'\n",
    "#             'neighborhood_overview VARCHAR,'\n",
    "#             'host_id INTEGER,'\n",
    "#             'host_url VARCHAR,'\n",
    "#             'host_name VARCHAR,'\n",
    "#             'host_since DATE,'\n",
    "#             'host_location VARCHAR,'\n",
    "#             'host_about VARCHAR,'\n",
    "#             'host_response_time VARCHAR,'\n",
    "#             'host_response_rate VARCHAR,'\n",
    "#             'host_acceptance_rate VARCHAR,'\n",
    "#             'host_is_superhost BOOLEAN,'\n",
    "#             'host_neighbourhood VARCHAR,'\n",
    "#             'host_listings_count INTEGER,'\n",
    "#             'host_total_listings_count INTEGER,'\n",
    "#             'host_verifications VARCHAR,'\n",
    "#             'host_has_profile_pic BOOLEAN,'\n",
    "#             'host_identity_verified BOOLEAN,'\n",
    "#             'neighbourhood_group VARCHAR,'\n",
    "#             'neighbourhood VARCHAR,'\n",
    "#             'neighbourhood_cleansed VARCHAR,'\n",
    "#             'neighbourhood_group_cleansed VARCHAR,'\n",
    "#             'latitude DOUBLE,'\n",
    "#             'longitude DOUBLE,'\n",
    "#             'property_type VARCHAR,'\n",
    "#             'room_type VARCHAR,'\n",
    "#             'accommodates INTEGER,'\n",
    "#             'bathrooms VARCHAR,'\n",
    "#             'bathrooms_text VARCHAR,'\n",
    "#             'bedrooms INTEGER,'\n",
    "#             'beds INTEGER,'\n",
    "#             'amenities VARCHAR,'\n",
    "#             'price INTEGER,'\n",
    "#             'minimum_nights INTEGER,'\n",
    "#             'maximum_nights INTEGER,'\n",
    "#             'minimum_minimum_nights INTEGER,'\n",
    "#             'maximum_minimum_nights INTEGER,'\n",
    "#             'minimum_maximum_nights INTEGER,'\n",
    "#             'maximum_maximum_nights INTEGER,'\n",
    "#             'minimum_nights_avg_ntm DOUBLE,'\n",
    "#             'maximum_nights_avg_ntm DOUBLE,'\n",
    "#             'calendar_updated VARCHAR,'\n",
    "#             'has_availability BOOLEAN,'\n",
    "#             'availability_30 INTEGER,'\n",
    "#             'availability_60 INTEGER,'\n",
    "#             'availability_90 INTEGER,'\n",
    "#             'availability_365 INTEGER,'\n",
    "#             'calendar_last_scraped DATE,'\n",
    "#             'number_of_reviews INTEGER,'\n",
    "#             'number_of_reviews_ltm INTEGER,'\n",
    "#             'number_of_reviews_l30d INTEGER,'\n",
    "#             'first_review DATE,'\n",
    "#             'last_review DATE,'\n",
    "#             'review_scores_rating DOUBLE,'\n",
    "#             'review_scores_accuracy DOUBLE,'\n",
    "#             'review_scores_cleanliness DOUBLE,'\n",
    "#             'review_scores_checkin DOUBLE,'\n",
    "#             'review_scores_communication DOUBLE,'\n",
    "#             'review_scores_location DOUBLE,'\n",
    "#             'review_scores_value DOUBLE,'\n",
    "#             'license VARCHAR,'\n",
    "#             'instant_bookable BOOLEAN,'            \n",
    "#             'calculated_host_listings_count INTEGER,'\n",
    "#             'calculated_host_listings_count_entire_homes INTEGER,'\n",
    "#             'calculated_host_listings_count_private_rooms INTEGER,'\n",
    "#             'calculated_host_listings_count_shared_rooms INTEGER,'\n",
    "#             'reviews_per_month DOUBLE,'\n",
    "#             'PRIMARY KEY(calendar_last_scraped, id))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original\n",
    "\n",
    "# con.execute(\"DROP TABLE IF EXISTS listings\")\n",
    "# con.execute(\"CREATE TABLE listings AS SELECT * FROM read_csv_auto('14Sep22 listings.csv');\")\n",
    "# con.execute(\"INSERT INTO listings SELECT * FROM read_csv_auto('11Jun22 listings.csv');\")\n",
    "# con.execute(\"INSERT INTO listings SELECT * FROM read_csv_auto('15Dec21 listings.csv');\")\n",
    "# con.execute(\"INSERT INTO listings SELECT * FROM read_csv_auto('19Mar22 listings.csv');\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('DROP TABLE IF EXISTS all_listings;')\n",
    "con.execute(\"CREATE TABLE all_listings AS SELECT * FROM read_csv_auto('14Sep22 listings 2.csv');\")\n",
    "con.execute(\"ALTER TABLE all_listings DROP source;\")\n",
    "con.execute(\"INSERT INTO all_listings SELECT * FROM read_csv_auto('11Jun22 listings 2.csv');\")\n",
    "con.execute(\"INSERT INTO all_listings SELECT * FROM read_csv_auto('15Dec21 listings 2.csv');\")\n",
    "con.execute(\"INSERT INTO all_listings SELECT * FROM read_csv_auto('19Mar22 listings 2.csv');\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceae168",
   "metadata": {},
   "source": [
    "#### Data Cleanup\n",
    "Change the price column to a numerical type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas version\n",
    "all_listings_df = con.execute(\"SELECT * from all_listings\").df()\n",
    "all_listings_df.price = all_listings_df.price.replace('\\$|,', '', regex=True).astype(float)\n",
    "con.execute('DROP TABLE IF EXISTS all_listings;')\n",
    "con.execute(\"CREATE TABLE all_listings AS SELECT * FROM all_listings_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL command version\n",
    "# con.execute('alter table all_listings rename price to price_text;')\n",
    "\n",
    "# con.execute('alter table all_listings add column price double;')\n",
    "# con.execute('''update all_listings set price = regexp_replace(price_text, '[$,]', '', 'g');''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a view for just the latest listings\n",
    "\n",
    "The all_listings table includes multiple entries for the same listing. We may want to just deal with one listing for the whole year, taking the latest data. This would weight each listing the same.  \n",
    "\n",
    "First, we need to determine the latest listing for each listing (e.g. when was the latest data scrape for listing 3686?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('drop view if exists last_scraped')\n",
    "con.execute('create view last_scraped as select id, max(calendar_last_scraped) as last_scraped from all_listings group by id;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a view called latest_listings that only takes the latest listing data for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('drop view if exists latest_listings')\n",
    "con.execute('create view latest_listings as select all_listings.* from all_listings inner join last_scraped on all_listings.id = last_scraped.id and all_listings.calendar_last_scraped = last_scraped.last_scraped; ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many listings are there compared to the entire data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10560,)]\n"
     ]
    }
   ],
   "source": [
    "con.execute(\"select count(id) from latest_listings;\")\n",
    "print(con.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 28076 total rows in the all_listings data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con.execute(\"select count(id) from latest_listings;\")\n",
    "print(con.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest_listings view, which only has one row per listing, has just 10560 rows, less than half of the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. neighborhood.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('DROP TABLE IF EXISTS neighborhoods;')\n",
    "con.execute('CREATE TABLE neighborhoods'\n",
    "            '(neighbourhood_group VARCHAR,'\n",
    "            'neighbourhood VARCHAR PRIMARY KEY,'\n",
    "            'type_outer VARCHAR,'\n",
    "            'feature_type VARCHAR,'\n",
    "            'geometry_type VARCHAR,'\n",
    "            'coordinates DOUBLE[][])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"11Jun22 neighbourhoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"11Jun22 neighbourhoods.geojson\", \"14Sep22 neighbourhoods.geojson\", \"15Dec21 neighbourhoods.geojson\", \"19Mar22 neighbourhoods.geojson\"]\n",
    "total = pd.DataFrame()\n",
    "last = pd.DataFrame(columns=[\"type_outer\", \"feature_type\", \"geometry_type\", \"coordinates\", \"neighborhood\", \"neighborhood group\"])\n",
    "diff = False\n",
    "for n in names:\n",
    "    with open(n, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "        row = []\n",
    "        type_outer = \"\"\n",
    "        type_outer = data[\"type\"]\n",
    "        features = []\n",
    "        feature_type = \"\"\n",
    "        geometry, properties = [], []\n",
    "        for y in range(0, len(data[\"features\"])):\n",
    "            features = data[\"features\"][y]\n",
    "            feature_type = features[\"type\"]\n",
    "            geometry = features[\"geometry\"]\n",
    "            properties = features[\"properties\"]\n",
    "            geometry_type, neigh, neigh_group = \"\", \"\", \"\"\n",
    "            coords = []\n",
    "            geometry_type = geometry[\"type\"]\n",
    "            coords = geometry[\"coordinates\"][0][0]\n",
    "            neigh = properties[\"neighbourhood\"]\n",
    "            neigh_group = properties[\"neighbourhood_group\"]\n",
    "            \n",
    "            if len(last) == 0:\n",
    "                row.append([type_outer, feature_type, geometry_type, coords, neigh, neigh_group])\n",
    "                diff = True\n",
    "                \n",
    "            elif list(last[last[\"neighborhood\"] == neigh][\"coordinates\"])[0] != list(coords):\n",
    "                lastcoords = list(last[last[\"neighborhood\"] == neigh][\"coordinates\"])[0]\n",
    "                diff = True\n",
    "                row.append([type_outer, feature_type, geometry_type, coords, neigh, neigh_group])\n",
    "        \n",
    "        if diff == True:\n",
    "            last = pd.DataFrame(row, columns=[\"type_outer\", \"feature_type\", \"geometry_type\", \"coordinates\", \"neighborhood\", \"neighborhood group\"])\n",
    "            json_df = pd.DataFrame(row, columns=[\"type_outer\", \"feature_type\", \"geometry_type\", \"coordinates\", \"neighborhood\", \"neighborhood group\"])\n",
    "            diff = False\n",
    "            \n",
    "            pd.concat([df, pd.read_csv(n.replace(\"geojson\", \"csv\"))])\n",
    "            df.drop_duplicates()\n",
    "            \n",
    "            new_df = df.join(json_df.set_index(\"neighborhood\"), on=\"neighbourhood\")\n",
    "            \n",
    "            total = pd.concat([total, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.drop(['neighborhood group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"INSERT INTO neighborhoods SELECT * FROM total;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('DROP TABLE IF EXISTS reviews;')\n",
    "con.execute('CREATE TABLE reviews'\n",
    "            '(listing_id BIGINT,'\n",
    "            'id BIGINT PRIMARY KEY,'\n",
    "            'date DATE,'\n",
    "            'reviewer_id INTEGER,'\n",
    "            'reviewer_name VARCHAR,'\n",
    "            'comments VARCHAR)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3571</td>\n",
       "      <td>36234</td>\n",
       "      <td>2010-04-18</td>\n",
       "      <td>81912</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Don's apartment is comfortable, clean and well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3571</td>\n",
       "      <td>51518</td>\n",
       "      <td>2010-06-10</td>\n",
       "      <td>112316</td>\n",
       "      <td>David</td>\n",
       "      <td>Don was a great host. He went out of his way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3571</td>\n",
       "      <td>132238</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>255952</td>\n",
       "      <td>Diana</td>\n",
       "      <td>This place was great! Don was extremely helpfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3571</td>\n",
       "      <td>326887</td>\n",
       "      <td>2011-06-21</td>\n",
       "      <td>637695</td>\n",
       "      <td>Monica</td>\n",
       "      <td>This condo was in a great location for touring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3571</td>\n",
       "      <td>368063</td>\n",
       "      <td>2011-07-12</td>\n",
       "      <td>448224</td>\n",
       "      <td>Florence</td>\n",
       "      <td>The apartment was very clean, comfortable and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321204</th>\n",
       "      <td>705262593266969561</td>\n",
       "      <td>709423398399592317</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>464219597</td>\n",
       "      <td>Charlene</td>\n",
       "      <td>Beautiful apartment, very safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321205</th>\n",
       "      <td>705307910480790712</td>\n",
       "      <td>709393953785783433</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>43384449</td>\n",
       "      <td>Rainer</td>\n",
       "      <td>Great quiet getaway in DC in residential neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321206</th>\n",
       "      <td>705307910480790712</td>\n",
       "      <td>713759649218625398</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>261620474</td>\n",
       "      <td>Ricardo</td>\n",
       "      <td>Nice and cozy stay, easy to find with self che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321207</th>\n",
       "      <td>708911697866238625</td>\n",
       "      <td>713003106344715260</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>225974179</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>Very accommodating. Great space with lots of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321208</th>\n",
       "      <td>709981492420435961</td>\n",
       "      <td>715160268061755802</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>353233332</td>\n",
       "      <td>Obi</td>\n",
       "      <td>Very attentive host &amp; answered all of my quest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321209 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                listing_id                  id        date  reviewer_id  \\\n",
       "0                     3571               36234  2010-04-18        81912   \n",
       "1                     3571               51518  2010-06-10       112316   \n",
       "2                     3571              132238  2010-11-02       255952   \n",
       "3                     3571              326887  2011-06-21       637695   \n",
       "4                     3571              368063  2011-07-12       448224   \n",
       "...                    ...                 ...         ...          ...   \n",
       "321204  705262593266969561  709423398399592317  2022-09-05    464219597   \n",
       "321205  705307910480790712  709393953785783433  2022-09-05     43384449   \n",
       "321206  705307910480790712  713759649218625398  2022-09-11    261620474   \n",
       "321207  708911697866238625  713003106344715260  2022-09-10    225974179   \n",
       "321208  709981492420435961  715160268061755802  2022-09-13    353233332   \n",
       "\n",
       "       reviewer_name                                           comments  \n",
       "0                Jon  Don's apartment is comfortable, clean and well...  \n",
       "1              David  Don was a great host. He went out of his way t...  \n",
       "2              Diana  This place was great! Don was extremely helpfu...  \n",
       "3             Monica  This condo was in a great location for touring...  \n",
       "4           Florence  The apartment was very clean, comfortable and ...  \n",
       "...              ...                                                ...  \n",
       "321204      Charlene                     Beautiful apartment, very safe  \n",
       "321205        Rainer  Great quiet getaway in DC in residential neigh...  \n",
       "321206       Ricardo  Nice and cozy stay, easy to find with self che...  \n",
       "321207        Johnny  Very accommodating. Great space with lots of a...  \n",
       "321208           Obi  Very attentive host & answered all of my quest...  \n",
       "\n",
       "[321209 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('14Sep22 reviews 2.csv')\n",
    "pd.concat([reviews_df, pd.read_csv('11Jun22 reviews 2.csv')])\n",
    "pd.concat([reviews_df, pd.read_csv('15Dec21 reviews 2.csv')])\n",
    "pd.concat([reviews_df, pd.read_csv('19Mar22 reviews 2.csv')])\n",
    "reviews_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"INSERT INTO reviews SELECT * FROM reviews_df;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to unzip the file for cleaning and rename it with a unique id\n",
    "def unzipcalendar(file,uniqueId):\n",
    "    new_file = 'calendar'+uniqueId+'.csv'\n",
    "    with gzip.open(file, 'r') as f_in, open(new_file, 'wb') as f_out:\n",
    "      shutil.copyfileobj(f_in, f_out)\n",
    "    print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleans the commas out of prices and adjusted_prices column and saves the data as a float back into the csv\n",
    "def cleanPrices(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['price'] = df['price'].str.replace(',', '').astype(float)\n",
    "        df['adjusted_price'] = df['adjusted_price'].str.replace(',', '').astype(float)\n",
    "        df.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the csv and remove '$' from the price data so it can be imported as int.\n",
    "# @arg filename (file.csv)\n",
    "# @arg match (string, e.g. '$', 'text')\n",
    "def cleancsv(filename, match):\n",
    "    original_file = filename\n",
    "    temp_file = \"temp.csv\"\n",
    "    \n",
    "    string_to_delete = [match]\n",
    "    with open(original_file, \"r\") as input:\n",
    "        with open(temp_file, \"w\") as output:\n",
    "            for line in input:\n",
    "                for word in string_to_delete:\n",
    "                    line = line.replace(word, \"\")\n",
    "                output.write(line)\n",
    "    os.replace('temp.csv', filename)\n",
    "    cleanPrices(filename)\n",
    "    print(filename, ' cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping and cleaning the files before we import into duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar12_2021.csv\n",
      "calendar03_2022.csv\n",
      "calendar06_2022.csv\n",
      "calendar09_2022.csv\n"
     ]
    }
   ],
   "source": [
    "unzipcalendar('15Dec21 calendar.csv.gz',\"12_2021\")\n",
    "unzipcalendar('19Mar22 calendar.csv.gz',\"03_2022\")\n",
    "unzipcalendar('11Jun22 calendar.csv.gz',\"06_2022\")\n",
    "unzipcalendar('14Sep22 calendar.csv.gz',\"09_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar12_2021.csv  cleaned\n",
      "calendar03_2022.csv  cleaned\n",
      "calendar06_2022.csv  cleaned\n",
      "calendar09_2022.csv  cleaned\n"
     ]
    }
   ],
   "source": [
    "cleancsv('calendar12_2021.csv','$')\n",
    "cleancsv('calendar03_2022.csv','$')\n",
    "cleancsv('calendar06_2022.csv','$')\n",
    "cleancsv('calendar09_2022.csv','$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv into duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('CREATE OR REPLACE TABLE calendar'\n",
    "            '(listing_id BIGINT,'\n",
    "            'date DATE,'\n",
    "            'available VARCHAR,'\n",
    "            'price INTEGER,'\n",
    "            'adjusted_price INTEGER,'\n",
    "            'minimum_nights INTEGER,'\n",
    "            'maximum_nights INTEGER);')\n",
    "con.execute(\"COPY calendar FROM 'calendar12_2021.csv' (AUTO_DETECT TRUE);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"INSERT INTO calendar SELECT * FROM read_csv('calendar09_2022.csv', delim=',', header=True, columns={'listing_id': 'BIGINT', 'date': 'DATE', 'available': 'VARCHAR', 'price': 'INTEGER', 'adjusted_price': 'INTEGER', 'minimum_nights': 'INTEGER', 'maximum_nights': 'INTEGER'});\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"INSERT INTO calendar SELECT * FROM read_csv_auto('calendar03_2022.csv');\")\n",
    "con.execute(\"INSERT INTO calendar SELECT * FROM read_csv_auto('calendar06_2022.csv');\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. crime.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('DROP TABLE IF EXISTS crimes;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con.execute('CREATE TABLE crimes'\n",
    "#             '(neighborhood_cluster VARCHAR,'\n",
    "#             'census_tract INTEGER,'\n",
    "#             'offensegroup VARCHAR,'\n",
    "#             'longitude DOUBLE,'\n",
    "#             'end_date VARCHAR,' # TODO: should definitely be DATE\n",
    "#             'offense_text VARCHAR,'\n",
    "#             'shift VARCHAR,'\n",
    "#             'yblock DOUBLE,'\n",
    "#             'district INTEGER,'\n",
    "#             'year INTEGER,'\n",
    "#             'ward INTEGER,'\n",
    "#             'offensekey VARCHAR,'\n",
    "#             'bid VARCHAR,'\n",
    "#             'sector VARCHAR,'\n",
    "#             'ucr_rank INTEGER,'\n",
    "#             'psa INTEGER,'\n",
    "#             'block_group VARCHAR,'\n",
    "#             'voting_precint VARCHAR,'\n",
    "#             'xblock DOUBLE,'\n",
    "#             'block VARCHAR,'\n",
    "#             'start_date VARCHAR,' # TODO: should definitely be DATE\n",
    "#             'ccn INTEGER,'\n",
    "#             'offense VARCHAR,'\n",
    "#             'octo_record_id VARCHAR,'\n",
    "#             'anc VARCHAR,'\n",
    "#             'report_dat VARCHAR,' # TODO: should definitely be DATE\n",
    "#             'method VARCHAR,'\n",
    "#             'location VARCHAR,' # TODO: should be DOUBLE[][] but also this column is redundant\n",
    "#             'latitude DOUBLE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.execute(\"INSERT INTO crimes SELECT * FROM read_csv('dc-crimes-search-results-V2.csv', dateformat='%m/%d/%Y, %H:%M:%S %p', AUTO_DETECT=TRUE);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x157966930>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"CREATE TABLE crimes as SELECT * FROM read_csv('dc-crimes-search-results-V2.csv', dateformat='%m/%d/%Y, %H:%M:%S %p', AUTO_DETECT=TRUE);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(27611,)]\n"
     ]
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(*) FROM crimes\")\n",
    "print(con.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all_listings', ['accommodates', 'amenities', 'availability_30', 'availability_365', 'availability_60', 'availability_90', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'calendar_last_scraped', 'calendar_updated', 'description', 'first_review', 'has_availability', 'host_about', 'host_acceptance_rate', 'host_has_profile_pic', 'host_id', 'host_identity_verified', 'host_is_superhost', 'host_listings_count', 'host_location', 'host_name', 'host_neighbourhood', 'host_picture_url', 'host_response_rate', 'host_response_time', 'host_since', 'host_thumbnail_url', 'host_total_listings_count', 'host_url', 'host_verifications', 'id', 'instant_bookable', 'last_review', 'last_scraped', 'latitude', 'license', 'listing_url', 'longitude', 'maximum_maximum_nights', 'maximum_minimum_nights', 'maximum_nights', 'maximum_nights_avg_ntm', 'minimum_maximum_nights', 'minimum_minimum_nights', 'minimum_nights', 'minimum_nights_avg_ntm', 'name', 'neighborhood_overview', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'number_of_reviews', 'number_of_reviews_l30d', 'number_of_reviews_ltm', 'picture_url', 'price', 'property_type', 'review_scores_accuracy', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value', 'reviews_per_month', 'room_type', 'scrape_id'], ['INTEGER', 'VARCHAR', 'INTEGER', 'INTEGER', 'INTEGER', 'INTEGER', 'VARCHAR', 'VARCHAR', 'INTEGER', 'INTEGER', 'INTEGER', 'INTEGER', 'INTEGER', 'INTEGER', 'DATE', 'VARCHAR', 'VARCHAR', 'DATE', 'BOOLEAN', 'VARCHAR', 'VARCHAR', 'BOOLEAN', 'INTEGER', 'BOOLEAN', 'BOOLEAN', 'INTEGER', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'DATE', 'VARCHAR', 'INTEGER', 'VARCHAR', 'VARCHAR', 'BIGINT', 'BOOLEAN', 'DATE', 'DATE', 'DOUBLE', 'VARCHAR', 'VARCHAR', 'DOUBLE', 'INTEGER', 'INTEGER', 'INTEGER', 'DOUBLE', 'INTEGER', 'INTEGER', 'INTEGER', 'DOUBLE', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'INTEGER', 'INTEGER', 'INTEGER', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'VARCHAR', 'BIGINT'], False), ('calendar', ['adjusted_price', 'available', 'date', 'listing_id', 'maximum_nights', 'minimum_nights', 'price'], ['INTEGER', 'VARCHAR', 'DATE', 'BIGINT', 'INTEGER', 'INTEGER', 'INTEGER'], False), ('crimes', ['ANC', 'BID', 'BLOCK', 'BLOCK_GROUP', 'CCN', 'CENSUS_TRACT', 'DISTRICT', 'END_DATE', 'LATITUDE', 'LONGITUDE', 'METHOD', 'NEIGHBORHOOD_CLUSTER', 'NEIGHBORHOOD_NAME', 'OCTO_RECORD_ID', 'OFFENSE', 'PSA', 'REPORT_DAT', 'SHIFT', 'START_DATE', 'VOTING_PRECINCT', 'WARD', 'XBLOCK', 'YBLOCK', 'YEAR', 'column00', 'location', 'offense-text', 'offensegroup', 'offensekey', 'sector', 'ucr-rank'], ['VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'INTEGER', 'DOUBLE', 'DOUBLE', 'VARCHAR', 'DOUBLE', 'DOUBLE', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'DOUBLE', 'DATE', 'VARCHAR', 'DATE', 'VARCHAR', 'DOUBLE', 'DOUBLE', 'DOUBLE', 'INTEGER', 'INTEGER', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'INTEGER'], False), ('neighborhoods', ['coordinates', 'feature_type', 'geometry_type', 'neighbourhood', 'neighbourhood_group', 'type_outer'], ['DOUBLE[][]', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR', 'VARCHAR'], False), ('reviews', ['comments', 'date', 'id', 'listing_id', 'reviewer_id', 'reviewer_name'], ['VARCHAR', 'DATE', 'BIGINT', 'BIGINT', 'INTEGER', 'VARCHAR'], False)]\n"
     ]
    }
   ],
   "source": [
    "con.execute(\"DESCRIBE\")\n",
    "print(con.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Crime Table\n",
    "For each neighborhood, this counts the number of offenses per type.  Of particular importance is the number of violent crimes in a neighborhood.\n",
    "\n",
    "Feel free to add to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('drop view if exists neighborhood_crimes')\n",
    "con.execute('create view neighborhood_crimes as Select neighborhood_name, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'homicide\\') as homicides, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'robbery\\') as robberies, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'assault w/dangerous weapon\\') as assaults, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'theft f/auto\\') as theft_from_auto, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'theft/other\\') as other_thefts, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'motor vehicle theft\\') as vehicle_theft, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'burglary\\') as burglaries, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'sex abuse\\') as sex_abuses, '\n",
    "        'count(neighborhood_name) FILTER (WHERE offense = \\'arson\\') as arsons,'\n",
    "        'count(neighborhood_name) FILTER (WHERE offensegroup = \\'violent\\') as violent_crimes,'\n",
    "        'count(neighborhood_name) FILTER (WHERE offensegroup = \\'property\\') as property_crimes,'\n",
    "        'count(neighborhood_name) as total_crimes '\n",
    "        'from crimes group by neighborhood_name;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Views\n",
    "\n",
    "\n",
    "#### Full Latest Listings\n",
    "\n",
    "This joins the latest listings to the neighborhood crime statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x161e791b0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs to be joined to crime aggregate table\n",
    "con.execute('drop view if exists full_latest_listings')\n",
    "con.execute('create view full_latest_listings as select * from latest_listings left join neighborhood_crimes on latest_listings.neighbourhood_cleansed = neighborhood_crimes.neighborhood_name;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the connection\n",
    "The duckdb file is locked until now... You'll have to close it to run CLI commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "757a43a63dbdd1886d37f8aeabe8f65b30b507bf5c396ccf6c5302a2be001ff1"
  },
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
